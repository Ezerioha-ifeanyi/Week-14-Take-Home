{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed66aba2",
   "metadata": {},
   "source": [
    "# Week 14: Data Pre-Processing & Regression - Student Assignments\n",
    "\n",
    "## Overview\n",
    "This document contains practical tasks, assignments, and assessments designed to test your understanding of data preprocessing techniques and regression analysis covered in Week 14.\n",
    "\n",
    "## Part 1: Tasks\n",
    "\n",
    "### Task 1: Missing Data Management\n",
    "**Objective**: Practice handling missing values in datasets\n",
    "\n",
    "**Dataset**: `Task-Datasets/task1_data_with_missing.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the provided dataset (15 rows with Name, Age, City, Income, Product_Rating)\n",
    "2. The dataset already contains missing values\n",
    "3. Handle the missing values using:\n",
    "   - Mean imputation\n",
    "   - Mode imputation\n",
    "4. Document your approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7cb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8902a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Income</th>\n",
       "      <th>Product_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age         City   Income  Product_Rating\n",
       "0   John  25.0     New York  45000.0             4.5\n",
       "1  Sarah  32.0  Los Angeles  62000.0             4.8\n",
       "2   Mike   NaN      Chicago  55000.0             4.2\n",
       "3  Emily  28.0      Houston      NaN             4.7\n",
       "4  David  45.0      Phoenix  78000.0             NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "taskData = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\DataraFlow Internship\\GitHub Pushing\\Week 14\\Week-14-Take-Home\\Task-Datasets\\task1_data_with_missing.csv\")\n",
    "\n",
    "# print the first 5 rows\n",
    "taskData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d3a82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Income</th>\n",
       "      <th>Product_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61416.666667</td>\n",
       "      <td>4.515385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.687845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10849.870827</td>\n",
       "      <td>0.260916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60500.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69750.000000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.000000</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name        Age      City        Income  Product_Rating\n",
       "count     15  12.000000        14     12.000000       13.000000\n",
       "unique    15        NaN        14           NaN             NaN\n",
       "top     John        NaN  New York           NaN             NaN\n",
       "freq       1        NaN         1           NaN             NaN\n",
       "mean     NaN  34.000000       NaN  61416.666667        4.515385\n",
       "std      NaN   6.687845       NaN  10849.870827        0.260916\n",
       "min      NaN  25.000000       NaN  45000.000000        4.100000\n",
       "25%      NaN  28.750000       NaN  54000.000000        4.300000\n",
       "50%      NaN  32.500000       NaN  60500.000000        4.500000\n",
       "75%      NaN  38.750000       NaN  69750.000000        4.700000\n",
       "max      NaN  45.000000       NaN  78000.000000        4.900000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the summary statistics of the data\n",
    "\n",
    "taskData.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9061b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Name            15 non-null     object \n",
      " 1   Age             12 non-null     float64\n",
      " 2   City            14 non-null     object \n",
      " 3   Income          12 non-null     float64\n",
      " 4   Product_Rating  13 non-null     float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 732.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# check the data information\n",
    "\n",
    "taskData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1371e5",
   "metadata": {},
   "source": [
    "- It is observed that the **Age** column has 3 missing values, **City** has 1 missing value, **Income** has 3 missing values, and **Product_rating** has 2 missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714abce8",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "- Since the features having missing values comprise of both numerical and categorical variables, we choose to fill the numerical variables with its mean and the categorical variable with its mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7f1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library to handle missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# create an imputer object with a mean filling strategy\n",
    "num_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "# fit the imputer object to the numerical columns (2nd, 4th, and 5th columns) and transform the data\n",
    "taskData.iloc[:, [1,3,4]] = num_imputer.fit_transform(taskData.iloc[:, [1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Income</th>\n",
       "      <th>Product_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>62000.000000</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>61416.666667</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>78000.000000</td>\n",
       "      <td>4.515385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67000.000000</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tom</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>51000.000000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anna</td>\n",
       "      <td>34.0</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>59000.000000</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris</td>\n",
       "      <td>41.0</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>72000.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>61416.666667</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mark</td>\n",
       "      <td>27.0</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>4.515385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Michelle</td>\n",
       "      <td>31.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>61416.666667</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brian</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name   Age           City        Income  Product_Rating\n",
       "0       John  25.0       New York  45000.000000        4.500000\n",
       "1      Sarah  32.0    Los Angeles  62000.000000        4.800000\n",
       "2       Mike  34.0        Chicago  55000.000000        4.200000\n",
       "3      Emily  28.0        Houston  61416.666667        4.700000\n",
       "4      David  45.0        Phoenix  78000.000000        4.515385\n",
       "5       Lisa  35.0            NaN  67000.000000        4.600000\n",
       "6        Tom  29.0   Philadelphia  51000.000000        4.300000\n",
       "7       Anna  34.0    San Antonio  59000.000000        4.900000\n",
       "8      Chris  41.0      San Diego  72000.000000        4.100000\n",
       "9    Jessica  33.0         Dallas  61416.666667        4.800000\n",
       "10      Mark  27.0       San Jose  48000.000000        4.515385\n",
       "11    Rachel  38.0         Austin  69000.000000        4.500000\n",
       "12     Kevin  34.0   Jacksonville  56000.000000        4.400000\n",
       "13  Michelle  31.0  San Francisco  61416.666667        4.700000\n",
       "14     Brian  44.0   Indianapolis  75000.000000        4.200000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that there are no missing values in the numerical columns\n",
    "\n",
    "taskData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a470c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library to handle missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# create an imputer object with a mode filling strategy\n",
    "cat_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "# fit the imputer object to the categorical column (3rd column) and transform the data\n",
    "taskData.iloc[:, 2] = cat_imputer.fit_transform(taskData.iloc[:, 2].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8576915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          New York\n",
       "1       Los Angeles\n",
       "2           Chicago\n",
       "3           Houston\n",
       "4           Phoenix\n",
       "5            Austin\n",
       "6      Philadelphia\n",
       "7       San Antonio\n",
       "8         San Diego\n",
       "9            Dallas\n",
       "10         San Jose\n",
       "11           Austin\n",
       "12     Jacksonville\n",
       "13    San Francisco\n",
       "14     Indianapolis\n",
       "Name: City, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskData.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4793a",
   "metadata": {},
   "source": [
    "## Approach to Task 1\n",
    "\n",
    "I began by importing the numpy, pandas and matplotlib li"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d328c2",
   "metadata": {},
   "source": [
    "### Task 2: Encoding Categorical Variables\n",
    "**Objective**: Master encoding techniques for categorical data\n",
    "\n",
    "**Dataset**: `Task-Datasets/task2_categorical_data.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the provided dataset with:\n",
    "   - Categorical independent variables: City, Product_Type\n",
    "   - Categorical dependent variable: Purchased (Yes/No)\n",
    "   - Numerical features: Age, Purchase_Amount\n",
    "2. Apply OneHotEncoder to City and Product_Type\n",
    "3. Apply LabelEncoder to the Purchased variable\n",
    "4. Print the shapes and first 5 rows before and after encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bf363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d2d585",
   "metadata": {},
   "source": [
    "### Task 3: Feature Scaling Comparison\n",
    "**Objective**: Understand the impact of feature scaling\n",
    "\n",
    "**Dataset**: `Task-Datasets/task3_scaling_data.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the provided dataset with features on different scales:\n",
    "   - Age: 23-46\n",
    "   - Annual_Salary: 32,000-108,000\n",
    "   - Years_Experience: 1-23\n",
    "   - Performance_Score: 71-95\n",
    "2. Split the data into training and test sets (80/20)\n",
    "3. Apply `StandardScaler` to both sets\n",
    "4. Create visualizations showing:\n",
    "   - Original data distribution\n",
    "   - Scaled data distribution\n",
    "5. Calculate and display the mean and standard deviation before and after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6680a49",
   "metadata": {},
   "source": [
    "## Part 2: Assignments\n",
    "\n",
    "### Assignment 1: Complete Data Preprocessing Pipeline\n",
    "**Objective**: Build an end-to-end preprocessing workflow\n",
    "\n",
    "**Scenario**: You have been provided with a messy customer dataset for an e-commerce company. The dataset contains information about customers including demographics, purchase history, and whether they made a repeat purchase.\n",
    "\n",
    "**Dataset**: `Assignment-Datasets/assignment1_ecommerce_data.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary**\n",
    "\n",
    "**Tasks**:\n",
    "1. **Data Loading & Exploration**:\n",
    "   - Load the dataset\n",
    "   - Display basic information (shape, data types, missing values count)\n",
    "   - Show statistical summary\n",
    "\n",
    "2. **Handle Missing Data**:\n",
    "   - Identify columns with missing values\n",
    "   - Apply appropriate imputation strategy\n",
    "   - Justify your choice of strategy\n",
    "\n",
    "3. **Encode Categorical Variables**:\n",
    "   - Encode using OneHotEncoder\n",
    "   - Encode LabelEncoder\n",
    "   - Handle the dummy variable trap\n",
    "\n",
    "4. **Split Dataset**:\n",
    "   - Create training and test sets (70/30 split)\n",
    "   - Set random_state=42 for reproducibility\n",
    "\n",
    "5. **Feature Scaling**:\n",
    "   - Apply StandardScaler to numerical features\n",
    "   - Ensure proper fit/transform methodology\n",
    "\n",
    "6. **Validation**:\n",
    "   - Print shapes of all final arrays\n",
    "   - Verify no missing values remain\n",
    "   - Display first 5 rows of processed training data\n",
    "\n",
    "**Deliverable**: \n",
    "- Complete preprocessing pipeline\n",
    "- Brief written report (markdown) explaining:\n",
    "  - Your preprocessing decisions\n",
    "  - Challenges encountered\n",
    "  - Why you chose specific techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028aa61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b595f3aa",
   "metadata": {},
   "source": [
    "### Assignment 2: Simple Linear Regression Analysis\n",
    "**Objective**: Implement and evaluate a simple linear regression model\n",
    "\n",
    "**Scenario**: A company wants to understand the relationship between advertising spend and sales revenue to optimize their marketing budget.\n",
    "\n",
    "**Dataset**: `Assignment-Datasets/assignment2_advertising_sales.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary**\n",
    "\n",
    "**Tasks**:\n",
    "1. **Data Preparation**:\n",
    "   - Load and explore the dataset\n",
    "   - Check for any data quality issues\n",
    "   - Create a scatter plot to visualize the relationship\n",
    "\n",
    "2. **Model Building**:\n",
    "   - Split data into training (70%) and test (30%) sets\n",
    "   - Build a simple linear regression model\n",
    "   - Fit the model on training data\n",
    "\n",
    "3. **Predictions**:\n",
    "   - Make predictions on both training and test sets\n",
    "   - Compare predicted vs actual values (show first 10)\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Create scatter plots with regression line for:\n",
    "     - Training set results\n",
    "     - Test set results\n",
    "   - Ensure proper labels, titles, and legends\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "   - Calculate R² score for both training and test sets\n",
    "   - Calculate Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
    "   - Interpret what these metrics tell you about model performance\n",
    "\n",
    "6. **Business Insights**:\n",
    "   - What is the equation of the regression line?\n",
    "   - If the company spends $50,000 on advertising, what sales revenue can they expect?\n",
    "   - Provide 3 business recommendations based on your analysis\n",
    "\n",
    "**Deliverable**:\n",
    "- Complete analysis\n",
    "- Visualizations\n",
    "- Report (markdown) with:\n",
    "  - Model performance metrics\n",
    "  - Regression equation\n",
    "  - Business insights and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bb15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f420cf",
   "metadata": {},
   "source": [
    "### Assignment 3: Multiple Linear Regression with Feature Selection\n",
    "**Objective**: Build a multiple regression model and optimize it using backward elimination\n",
    "\n",
    "**Scenario**: A startup company wants to predict their monthly profit based on various business metrics. You need to build a model and identify which factors most significantly impact profit.\n",
    "\n",
    "**Dataset**: `Assignment-Datasets/assignment3_startup_profit.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary**\n",
    "\n",
    "**Tasks**:\n",
    "1. **Data Preprocessing**:\n",
    "   - Load and explore the dataset\n",
    "   - Encode the categorical variable (Location)\n",
    "   - Avoid the dummy variable trap\n",
    "   - Split into training (80%) and test (20%) sets\n",
    "\n",
    "2. **Initial Model**:\n",
    "   - Build a multiple linear regression model using all features\n",
    "   - Fit the model on training data\n",
    "   - Make predictions on test set\n",
    "\n",
    "3. **Model Evaluation (Initial)**:\n",
    "   - Calculate R² score\n",
    "   - Calculate adjusted R² score\n",
    "   - Calculate MSE and RMSE\n",
    "\n",
    "4. **Feature Selection using Backward Elimination**:\n",
    "   - Add a column of ones for the intercept\n",
    "   - Use statsmodels OLS to get p-values\n",
    "   - Remove features with p-value > 0.05 iteratively\n",
    "   - Document each step of elimination with justification\n",
    "\n",
    "5. **Optimized Model**:\n",
    "   - Rebuild the model with selected features only\n",
    "   - Compare performance with initial model\n",
    "   - Create a comparison table\n",
    "\n",
    "6. **Visualization**:\n",
    "   - Create a bar chart comparing actual vs predicted profits (top 10 samples)\n",
    "   - Create a residual plot\n",
    "   - Create a feature importance visualization\n",
    "\n",
    "7. **Analysis Report**:\n",
    "   - Which features were most significant?\n",
    "   - How much did model performance improve after optimization?\n",
    "   - What business recommendations can you provide?\n",
    "\n",
    "**Deliverable**:\n",
    "- Complete implementation\n",
    "- Visualizations\n",
    "- Comprehensive report (markdown) with:\n",
    "  - Backward elimination steps documented\n",
    "  - Model comparison table\n",
    "  - Feature importance analysis\n",
    "  - Business recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba78d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d25819e",
   "metadata": {},
   "source": [
    "## Part 3: Assessment\n",
    "\n",
    "### Real-World Project: Housing Price Prediction\n",
    "\n",
    "**Objective**: Apply all learned concepts in a complete machine learning project\n",
    "\n",
    "**Scenario**: You are a data scientist at a real estate company. The company wants to develop a model to predict house prices based on various features to help with property valuation.\n",
    "\n",
    "**Dataset**: `Assessment-Dataset/housing_price_data.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary**\n",
    "\n",
    "**Project Requirements**:\n",
    "\n",
    "### Phase 1: Data Understanding & Preprocessing\n",
    "1. Load and perform exploratory data analysis (EDA):\n",
    "   - Dataset shape and structure\n",
    "   - Statistical summaries\n",
    "   - Distribution of target variable\n",
    "   - Correlation analysis with heatmap\n",
    "\n",
    "2. Data Quality Assessment:\n",
    "   - Identify and handle missing values\n",
    "   - Detect and handle outliers if any\n",
    "   - Document all data quality observations\n",
    "\n",
    "3. Complete Preprocessing Pipeline:\n",
    "   - Encode categorical variables appropriately (Neighborhood, Garage, Pool)\n",
    "   - Handle dummy variable trap\n",
    "   - Split data (70% train, 30% test)\n",
    "   - Apply feature scaling where appropriate\n",
    "\n",
    "### Phase 2: Model Development\n",
    "1. Build and compare TWO models:\n",
    "   - **Model 1**: Multiple Linear Regression with all features\n",
    "   - **Model 2**: Optimized Multiple Linear Regression (after feature selection)\n",
    "\n",
    "2. For each model, perform:\n",
    "   - Training on training set\n",
    "   - Predictions on test set\n",
    "   - Complete evaluation metrics:\n",
    "     - R² score\n",
    "     - Adjusted R² score\n",
    "     - Mean Absolute Error (MAE)\n",
    "     - Mean Squared Error (MSE)\n",
    "     - Root Mean Squared Error (RMSE)\n",
    "\n",
    "3. Feature Selection:\n",
    "   - Apply backward elimination (significance level = 0.05)\n",
    "   - Document each elimination step\n",
    "   - Justify the final feature set\n",
    "\n",
    "### Phase 3: Model Evaluation & Validation\n",
    "1. Create comprehensive visualizations:\n",
    "   - Scatter plot: Predicted vs Actual prices (both models)\n",
    "   - Residual plots (both models)\n",
    "   - Feature importance/coefficient visualization\n",
    "   - Distribution of prediction errors\n",
    "\n",
    "2. Model Comparison:\n",
    "   - Create a comparison table\n",
    "   - Analyze which model performs better\n",
    "   - Discuss overfitting/underfitting if present\n",
    "\n",
    "3. Cross-validation (Bonus):\n",
    "   - Implement k-fold cross-validation\n",
    "   - Report average scores\n",
    "\n",
    "### Phase 4: Business Insights & Recommendations\n",
    "1. Interpret the model:\n",
    "   - Which features most strongly influence house prices?\n",
    "   - What is the price impact of each significant feature?\n",
    "   - Are there any surprising findings?\n",
    "\n",
    "2. Provide actionable recommendations:\n",
    "   - How can the real estate company use this model?\n",
    "   - What are the limitations of the current model?\n",
    "   - What improvements would you suggest?\n",
    "\n",
    "3. Make sample predictions:\n",
    "   - Create 3 hypothetical houses with different characteristics\n",
    "   - Predict their prices\n",
    "   - Explain the predictions\n",
    "\n",
    "**Deliverables**:\n",
    "1. **With**:\n",
    "   - Well-organized sections matching project phases\n",
    "   - Clear markdown cells for explanations\n",
    "   - Clean, commented code\n",
    "   - All visualizations embedded\n",
    "\n",
    "2. **Your Code** must contain:\n",
    "   - Reusable preprocessing function\n",
    "   - Model training function\n",
    "   - Evaluation function\n",
    "\n",
    "3. **Comprehensive Report** (In a Markdown Cell With):\n",
    "   - Executive summary\n",
    "   - Methodology\n",
    "   - Results and findings\n",
    "   - Recommendations\n",
    "   - Appendix with key visualizations\n",
    "\n",
    "**Note**: The dataset `Assessment-Dataset/housing_price_data.csv` is provided for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa25ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d77e73",
   "metadata": {},
   "source": [
    "## Bonus Challenges\n",
    "\n",
    "If you want to go beyond:\n",
    "\n",
    "1. **Advanced Feature Engineering**:\n",
    "   - Create polynomial features\n",
    "   - Implement feature interactions\n",
    "   - Compare performance\n",
    "\n",
    "2. **Alternative Regression Techniques**:\n",
    "   - Try Ridge Regression\n",
    "   - Try Lasso Regression\n",
    "   - Compare with standard linear regression\n",
    "\n",
    "3. **Hyperparameter Tuning**:\n",
    "   - Use GridSearchCV for model optimization\n",
    "   - Document the improvement\n",
    "\n",
    "4. **Real-World Dataset**:\n",
    "   - Find a dataset from Kaggle or UCI ML Repository\n",
    "   - Apply all learned techniques\n",
    "   - Present findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2df18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9bf471c",
   "metadata": {},
   "source": [
    "## Link to your publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2ae0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46a29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fef853",
   "metadata": {},
   "source": [
    "**Good luck with your assignments! Remember, the goal is not just to complete the tasks, but to truly understand the concepts and be able to apply them to real-world problems.** \n",
    "\n",
    "## Merry Christmas !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b3eaa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
